{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOjukG/ZEa5HJmXSWs1X5x+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kilzol/Amazon-web-services/blob/master/presentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PRE PROCESSING/ DATA CLEANING**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I8JiQFjc_ZBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tsurumeso/vocal-remover.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CRYOLorRs3U",
        "outputId": "e03a2894-ae9c-40b1-add4-ada66d3b1eb8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vocal-remover'...\n",
            "remote: Enumerating objects: 639, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 639 (delta 6), reused 10 (delta 4), pack-reused 618\u001b[K\n",
            "Receiving objects: 100% (639/639), 149.17 KiB | 16.57 MiB/s, done.\n",
            "Resolving deltas: 100% (385/385), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd vocal-remover"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ3DCSwcSoCV",
        "outputId": "7d4b3369-7bcb-4972-aaf3-1b849babcb6c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/vocal-remover\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install resampy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tQGk7LRWe5-",
        "outputId": "ffcf0e90-b341-4c43-864b-6f4ab264a8de"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting resampy\n",
            "  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/3.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from resampy) (1.22.4)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.10/dist-packages (from resampy) (0.56.4)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.53->resampy) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.53->resampy) (67.7.2)\n",
            "Installing collected packages: resampy\n",
            "Successfully installed resampy-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0730 H  ON 02 AUG 2023 (08) (2)**"
      ],
      "metadata": {
        "id": "4Dp9vX5r1zIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py --input /content/audio1.wav --output_dir output --gpu 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vIhTrltTBGv",
        "outputId": "f3e9163a-791d-417d-f5b8-96de3e87065c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model... done\n",
            "loading wave source... done\n",
            "stft of wave source... done\n",
            "100% 4/4 [01:06<00:00, 16.69s/it]\n",
            "validating output directory... done\n",
            "inverse stft of instruments... done\n",
            "inverse stft of vocals... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0800 H   02 AUG 2023 (01)**"
      ],
      "metadata": {
        "id": "XjKDGALC7Rdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py --input /content/audio2.wav --output_dir output --gpu 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7TlzhXB7ZzJ",
        "outputId": "6fdbfbff-fefe-449e-e055-2aacb27899e0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model... done\n",
            "loading wave source... done\n",
            "stft of wave source... done\n",
            "100% 7/7 [02:00<00:00, 17.17s/it]\n",
            "validating output directory... done\n",
            "inverse stft of instruments... done\n",
            "inverse stft of vocals... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0805 H  02 AUG 2023 (02)**"
      ],
      "metadata": {
        "id": "Jn2RJZGKNSb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py --input /content/audio3.wav --output_dir output --gpu 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhOjOgOyNdOt",
        "outputId": "5137d3cf-bc88-490b-8040-23dd93e4274d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model... done\n",
            "loading wave source... done\n",
            "stft of wave source... done\n",
            "100% 7/7 [01:48<00:00, 15.46s/it]\n",
            "validating output directory... done\n",
            "inverse stft of instruments... done\n",
            "inverse stft of vocals... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0810  ON 02 AUG 2023 (03) (1)**"
      ],
      "metadata": {
        "id": "90HrHgfxeawN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py --input /content/audio4.wav --output_dir output --gpu 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EM0vJBZceedN",
        "outputId": "29c63af3-d33c-4775-d759-b9c5b42ae7c3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model... done\n",
            "loading wave source... done\n",
            "stft of wave source... done\n",
            "100% 4/4 [01:10<00:00, 17.54s/it]\n",
            "validating output directory... done\n",
            "inverse stft of instruments... done\n",
            "inverse stft of vocals... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0915 H   02 AUG 2023 (01) (1)**\n"
      ],
      "metadata": {
        "id": "WLpbSlr-0BtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py --input /content/audio5.wav --output_dir output --gpu 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D3PUiBD0KBR",
        "outputId": "69cbd958-84b1-499d-c9e4-a6c216e4d27e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model... done\n",
            "loading wave source... done\n",
            "stft of wave source... done\n",
            "100% 6/6 [00:01<00:00,  3.24it/s]\n",
            "validating output directory... done\n",
            "inverse stft of instruments... done\n",
            "inverse stft of vocals... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0950 H 02 AUG 2023 (01) (1)**"
      ],
      "metadata": {
        "id": "f3cuQsHUzjgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py --input /content/audio6.wav --output_dir output --gpu 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud6DUpREzk8H",
        "outputId": "96ef5afe-1ea2-406d-f658-e83b7ac8515e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model... done\n",
            "loading wave source... done\n",
            "stft of wave source... done\n",
            "100% 4/4 [00:01<00:00,  2.56it/s]\n",
            "validating output directory... done\n",
            "inverse stft of instruments... done\n",
            "inverse stft of vocals... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1350 H 02 AUG 2023 (01)**"
      ],
      "metadata": {
        "id": "egsTa3pa0J2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py --input /content/audio7.wav --output_dir output --gpu 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrSJct6m0OPV",
        "outputId": "ca6df5f2-72f3-4f04-dcab-76c39c561fbe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model... done\n",
            "loading wave source... done\n",
            "stft of wave source... done\n",
            "100% 11/11 [00:03<00:00,  3.57it/s]\n",
            "validating output directory... done\n",
            "inverse stft of instruments... done\n",
            "inverse stft of vocals... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1405 H   AS ON 02 AUG 2023 (01) (1)**"
      ],
      "metadata": {
        "id": "i4na7T5s0Tdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py --input /content/audio8.wav --output_dir output --gpu 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJ0A70oR0V4S",
        "outputId": "f47cd684-912f-4b3e-eaf0-ce4f2800e9e5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model... done\n",
            "loading wave source... done\n",
            "stft of wave source... done\n",
            "100% 8/8 [00:02<00:00,  3.68it/s]\n",
            "validating output directory... done\n",
            "inverse stft of instruments... done\n",
            "inverse stft of vocals... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1635 H   AS ON 02 AUG 2023 (01) (1)**"
      ],
      "metadata": {
        "id": "hSDawipF1pBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py --input /content/audio9.wav --output_dir output --gpu 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MA230Tgu1s1J",
        "outputId": "a0c95cce-8855-4848-a680-b84deb765117"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model... done\n",
            "loading wave source... done\n",
            "stft of wave source... done\n",
            "100% 8/8 [00:02<00:00,  3.73it/s]\n",
            "validating output directory... done\n",
            "inverse stft of instruments... done\n",
            "inverse stft of vocals... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1640 H  AS ON 02 AUG 2023 (02) (1)**"
      ],
      "metadata": {
        "id": "FWGPr7es15gR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py --input /content/audio10.wav --output_dir output --gpu 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5xvsvXN18ZU",
        "outputId": "d941cbd5-68e1-43f1-f42f-5600de37af7a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model... done\n",
            "loading wave source... done\n",
            "stft of wave source... done\n",
            "100% 5/5 [00:01<00:00,  3.01it/s]\n",
            "validating output directory... done\n",
            "inverse stft of instruments... done\n",
            "inverse stft of vocals... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SPEECH TO TEXT USING WHISPER.AI**\n"
      ],
      "metadata": {
        "id": "u3I0fIQuRwCB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zilq2Lrp-f9c",
        "outputId": "aab54339-80fe-41c2-ead8-740465c5ffec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-uwsb62ki\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-uwsb62ki\n",
            "  Resolved https://github.com/openai/whisper.git to commit b91c907694f96a3fb9da03d4bbdc83fbcd3a40a4\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (4.65.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (9.1.0)\n",
            "Collecting tiktoken==0.3.3 (from openai-whisper==20230314)\n",
            "  Downloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper==20230314) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper==20230314) (2.27.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.12.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314) (16.0.6)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230314) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230314) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (3.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20230314) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20230314) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=798284 sha256=dcc352474b48f753087ced5327b7f75a63e572bf271ba34f84ccab620e859280\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mlcoya_e/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20230314 tiktoken-0.3.3\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [43.3 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [456 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [833 kB]\n",
            "Get:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [979 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,235 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,103 kB]\n",
            "Hit:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [25.6 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [49.2 kB]\n",
            "Get:19 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [21.7 kB]\n",
            "Fetched 5,107 kB in 4s (1,312 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "30 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0730 H  ON 02 AUG 2023 (08) (2)**"
      ],
      "metadata": {
        "id": "7ZOjRrZzCZ8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper output/audio1_Vocals.wav --task translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1oEaGGz-8iZ",
        "outputId": "d9056648-29ce-47ea-f865-1278dd4e3dbb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:39<00:00, 12.2MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Arabic\n",
            "[00:00.000 --> 00:10.000]  I'm not sure.\n",
            "[00:10.000 --> 00:38.000]  I'm not sure.\n",
            "[00:38.000 --> 00:43.000]  I'm not sure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0730 H  ON 02 AUG 2023 (08) (2)    SPECIFING THE LANGUAGE**"
      ],
      "metadata": {
        "id": "MtS4Q1Zt3Rug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper output/audio1_Vocals.wav --language Chinese --task translate"
      ],
      "metadata": {
        "id": "tWJCahCXA3c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfa9f493-d674-4844-f9cf-86244d2f4c1f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "[00:00.000 --> 00:11.400]  People say that Henri Ba!\n",
            "[00:11.400 --> 00:16.200]  You can call it about passion, man.\n",
            "[00:16.200 --> 00:24.920]  Feel like it's enough, man.\n",
            "[00:24.920 --> 00:29.220]  It is a very good thing that I am very happy to see you here.\n",
            "[00:29.220 --> 00:31.220]  Thank you very much, thank you very much!\n",
            "[00:31.220 --> 00:33.220]  Thank you very much!\n",
            "[00:33.220 --> 00:35.220]  Thank you very much!\n",
            "[00:35.220 --> 00:37.220]  Thank you very much!\n",
            "[00:37.220 --> 00:39.220]  Thank you very much!\n",
            "[00:39.220 --> 00:41.220]  Thank you very much!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0800 H 02 AUG 2023 (01)**\n"
      ],
      "metadata": {
        "id": "tXt1FMXL-cSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper output/audio2_Vocals.wav --task translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLw-XQRN-nlk",
        "outputId": "5e06bfa7-2ffc-43a9-d1df-669a045d9b7d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Javanese\n",
            "[00:00.000 --> 00:30.000]  I don't know what I'm saying, I don't know what I'm saying, I don't know what I'm saying, I don't know what I'm saying, I don't know what I'm saying, I don't know what I'm saying, I don't know what I'm saying, I don't know what I'm saying, I don't know what I'm saying, I don't know what I'm saying, I don't know what I'm saying, I don't know what I'm saying, I don't know what I'm saying, I don't know what I'm saying, I don't know what I'm saying, I don't know what I'm saying, I don't know what I'm saying, I don't know what I'm saying, I don't know what I'm saying, I don't know what I'm saying, I don't know what I'm saying, I don't know what I'm saying, I don't know what I'm saying, I don't know what I'm saying, I don't know what I'm\n",
            "[00:30.000 --> 00:45.760]  saying, I don't know what I'm saying, I don't know what I'm saying, I don't know what I'm saying,\n",
            "[00:45.760 --> 00:52.340]  No, I have been\n",
            "[00:52.340 --> 01:02.620]  there for a long time.\n",
            "[01:02.620 --> 01:07.760]  Yeah.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0800 H 02 AUG 2023 (01) SPECIFING LANGUAGE**"
      ],
      "metadata": {
        "id": "c4ml1rQC_ApX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper output/audio2_Vocals.wav --language Chinese --task translate"
      ],
      "metadata": {
        "id": "ZuLk_4IP_V2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "174ec880-851c-4518-d261-9a86b7345d6a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "[00:00.000 --> 00:30.000]  I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do, I don't know what to do\n",
            "[00:30.000 --> 00:40.920]  in your life, what does it mean to say you will see your lyre ?\n",
            "[00:40.920 --> 00:48.380]  I can't understand it but I don't know what I believe, the truth is true, many run嫉.\n",
            "[00:49.820 --> 00:55.900]  but in my life, I did not believe so much, I didn't believe so much, it was funny.\n",
            "[00:55.900 --> 01:05.460]  You forget for a moment, that you're a正確 person!\n",
            "[01:05.460 --> 01:07.640]  Just normal understanding\n",
            "[01:07.660 --> 01:11.220] 真正確實!\n",
            "[01:11.220 --> 01:13.900]  When there is such a matter, mine becomes false!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0805 H 02 AUG 2023 (02)**"
      ],
      "metadata": {
        "id": "QnpLs1ZrQxm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper output/audio3_Vocals.wav --task translate"
      ],
      "metadata": {
        "id": "anohJSb_c-H9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c4ac6fc-13e0-4732-c45a-ba5d5520f32b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Myanmar\n",
            "[00:00.000 --> 00:02.000]  we are\n",
            "[00:02.180 --> 00:05.440]  he broader real world\n",
            "[00:10.380 --> 00:13.620]  I denied him\n",
            "[00:24.720 --> 00:27.040]  not real material\n",
            "[00:32.000 --> 00:34.000]  I'm going to show you how to do it.\n",
            "[00:34.000 --> 00:36.000]  I'm going to show you how to do it.\n",
            "[00:36.000 --> 00:38.000]  I'm going to show you how to do it.\n",
            "[00:38.000 --> 00:40.000]  I'm going to show you how to do it.\n",
            "[00:40.000 --> 00:42.000]  I'm going to show you how to do it.\n",
            "[00:42.000 --> 00:44.000]  I'm going to show you how to do it.\n",
            "[00:44.000 --> 00:46.000]  I'm going to show you how to do it.\n",
            "[00:46.000 --> 00:48.000]  I'm going to show you how to do it.\n",
            "[00:48.000 --> 00:50.000]  I'm going to show you how to do it.\n",
            "[00:50.000 --> 00:52.000]  I'm going to show you how to do it.\n",
            "[00:52.000 --> 00:54.000]  I'm going to show you how to do it.\n",
            "[00:54.000 --> 00:56.000]  I'm going to show you how to do it.\n",
            "[00:56.000 --> 00:58.000]  I'm going to show you how to do it.\n",
            "[00:58.000 --> 01:00.000]  I'm going to show you how to do it.\n",
            "[01:00.000 --> 01:02.000]  I'm going to show you how to do it.\n",
            "[01:02.000 --> 01:04.000]  I'm going to show you how to do it.\n",
            "[01:07.000 --> 01:09.000]  I'm going to show you how to do it.\n",
            "[01:09.000 --> 01:11.000]  I'm going to show you how to do it.\n",
            "[01:11.000 --> 01:13.000]  I'm going to show you how to do it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0805 H 02 AUG 2023 (02) SPECIFING THE LANGUAGE**"
      ],
      "metadata": {
        "id": "jzqS8OPeSJo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper output/audio3_Vocals.wav --language Chinese --task translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95fNLtv1SWYi",
        "outputId": "160d462a-3558-43c6-da6a-d41f8f955726"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "[00:00.000 --> 00:04.820]  you can see here, Chairman Li visited the system\n",
            "[00:05.060 --> 00:07.860]  and I watched the notes\n",
            "[00:07.960 --> 00:09.760]  I remembered all that\n",
            "[00:09.900 --> 00:19.580]  and when we were small, pretty little\n",
            "[00:20.040 --> 00:26.640]  She told me she was still doing it\n",
            "[00:26.640 --> 00:56.640]  I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm\n",
            "[00:56.640 --> 01:12.600]  doing, I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm doing, I don't know what I'm doing,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0810 ON 02 AUG 2023 (03) (1)**"
      ],
      "metadata": {
        "id": "WQ1T5pDOi2xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper output/audio4_Vocals.wav --task translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehkGm0w6i_Ji",
        "outputId": "59a51299-796d-48b8-c73b-e9d6769c3a2b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Myanmar\n",
            "[00:00.000 --> 00:30.000]  I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't\n",
            "[00:30.000 --> 00:46.460]  know what you're talking about, I don't know what you're talking about, I don't know what you're talking okay okay okay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0810 ON 02 AUG 2023 (03) (1) SPECIFING THE LANGUAGE**"
      ],
      "metadata": {
        "id": "hSkXUWt7nSb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper output/audio4_Vocals.wav --language Chinese --task translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aj_JrtfdnbDg",
        "outputId": "cee67cd6-31f9-43c7-9c47-66a41064f06f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "[00:00.000 --> 00:04.000]  This is the first time I've ever seen someone like this in my life.\n",
            "[00:04.000 --> 00:06.000]  This is the first time I've ever seen someone like this in my life.\n",
            "[00:06.000 --> 00:08.000]  This is the first time I've ever seen someone like this in my life.\n",
            "[00:08.000 --> 00:10.000]  This is the first time I've ever seen someone like this in my life.\n",
            "[00:10.000 --> 00:12.000]  This is the first time I've ever seen someone like this in my life.\n",
            "[00:12.000 --> 00:14.000]  This is the first time I've ever seen someone like this in my life.\n",
            "[00:14.000 --> 00:16.000]  This is the first time I've ever seen someone like this in my life.\n",
            "[00:16.000 --> 00:18.000]  This is the first time I've ever seen someone like this in my life.\n",
            "[00:18.000 --> 00:20.000]  This is the first time I've ever seen someone like this in my life.\n",
            "[00:20.000 --> 00:22.000]  This is the first time I've ever seen someone like this in my life.\n",
            "[00:22.000 --> 00:24.000]  This is the first time I've ever seen someone like this in my life.\n",
            "[00:24.000 --> 00:26.000]  This is the first time I've ever seen someone like this in my life.\n",
            "[00:26.000 --> 00:28.000]  This is the first time I've ever seen someone like this in my life.\n",
            "[00:28.000 --> 00:30.000]  This is the first time I've ever seen someone like this in my life.\n",
            "[00:30.000 --> 00:32.000]  This is the first time I've ever seen someone like this in my life.\n",
            "[00:32.000 --> 00:34.000]  This is the first time I've ever seen someone like this in my life.\n",
            "[00:34.000 --> 00:36.000]  This is the first time I've ever seen someone like this in my life.\n",
            "[00:38.000 --> 00:40.000]  This is the first time I've ever seen someone like this in my life.\n",
            "[00:40.000 --> 00:42.000]  This is the first time I've ever seen someone like this in my life.\n",
            "[00:42.000 --> 00:44.000]  This is the first time I've ever seen someone like this in my life.\n",
            "[00:44.000 --> 00:46.000]  This is the first time I've ever seen someone like this in my life.\n",
            "[00:46.000 --> 00:48.000]  This is the first time I've ever seen someone like this in my life.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0915 H 02 AUG 2023 (01) (1)**"
      ],
      "metadata": {
        "id": "B3sOOKG3wbSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper output/audio5_Vocals.wav --task translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLxeIga3wdnJ",
        "outputId": "a68721e1-4aca-4528-98ee-5a5bf4cc4846"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Javanese\n",
            "[00:00.000 --> 00:30.000]  I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't know what you're talking about, I don't\n",
            "[00:30.000 --> 00:47.600]  know what you're talking about, I don't know what you're talking about, I haven't seen you.\n",
            "[00:47.600 --> 01:00.660]  the\n",
            "[01:00.660 --> 01:01.400]  now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0915 H 02 AUG 2023 (01) (1) SPECIFING THE LANGUAGE**"
      ],
      "metadata": {
        "id": "anc8T-VzxOb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper output/audio5_Vocals.wav --language Chinese --task translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nebONV5xUxv",
        "outputId": "45e83766-6d7c-414c-b1ac-a8adcaaaa921"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:05.000]  This is the first time I've ever seen someone like this in my life.\n",
            "[00:05.000 --> 00:09.000]  I've never seen anyone like this in my life.\n",
            "[00:09.000 --> 00:13.000]  I've never seen anyone like this in my life.\n",
            "[00:13.000 --> 00:18.000]  I've never seen anyone like this in my life.\n",
            "[00:18.000 --> 00:22.000]  I've never seen anyone like this in my life.\n",
            "[00:22.000 --> 00:26.000]  I've never seen anyone like this in my life.\n",
            "[00:26.000 --> 00:29.000]  I've never seen anyone like this in my life.\n",
            "[00:29.000 --> 00:33.000]  I've never seen anyone like this in my life.\n",
            "[00:33.000 --> 00:37.000]  I've never seen anyone like this in my life.\n",
            "[00:37.000 --> 00:42.000]  I've never seen anyone like this in my life.\n",
            "[00:44.000 --> 00:48.000]  I've never seen anyone like this in my life.\n",
            "[00:48.000 --> 00:53.000]  I've never seen anyone like this in my life.\n",
            "[00:53.000 --> 00:58.200]  I don't believe those who think I'm am者 ...\n",
            "[00:58.200 --> 00:59.600]  Hope you enjoyed watching this video.\n",
            "[00:59.740 --> 01:01.600]  Happy QQ gathering!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0950 H   02 AUG 2023 (01) (1)**"
      ],
      "metadata": {
        "id": "S1NYlRfKzFA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper output/audio6_Vocals.wav --task translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HWD27VfzJh4",
        "outputId": "ef172fa7-d3f5-4d02-cf69-d9fff63910f9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: English\n",
            "[00:00.000 --> 00:30.000]  Yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah\n",
            "[00:30.000 --> 00:35.680]  yeah\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0950 H 02 AUG 2023 (01) (1) SPECIFING THE LANGUAGE**"
      ],
      "metadata": {
        "id": "WMxMBfMizN-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper output/audio6_Vocals.wav --language Chinese --task translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da-yMdKCzTHQ",
        "outputId": "14d0b15a-7226-459f-a545-556c815406b7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:06.000]  This is the first time I've ever seen a person like this in my life.\n",
            "[00:06.000 --> 00:10.000]  This is the first time I've ever seen a person like this in my life.\n",
            "[00:10.000 --> 00:14.000]  This is the first time I've ever seen a person like this in my life.\n",
            "[00:14.000 --> 00:18.000]  This is the first time I've ever seen a person like this in my life.\n",
            "[00:18.000 --> 00:22.000]  This is the first time I've ever seen a person like this in my life.\n",
            "[00:22.000 --> 00:26.000]  This is the first time I've ever seen a person like this.\n",
            "[00:26.000 --> 00:31.000]  This is the first time I've ever seen a person like this in my life.\n",
            "[00:31.000 --> 00:36.000]  This is the first time I've ever seen a person like this in my life.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1350 H  02 AUG 2023 (01)**"
      ],
      "metadata": {
        "id": "zgMzh2_Tzr2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper output/audio7_Vocals.wav --task translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaVaH-3rzvUI",
        "outputId": "9fbd0617-2aff-4444-ef81-fced1c1d4d65"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Myanmar\n",
            "[00:00.000 --> 00:30.000]  It is very difficult to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a\n",
            "[00:30.000 --> 00:44.080]  way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find the way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a way to find a dog.\n",
            "[01:30.000 --> 01:40.000]  I'm going to show you how to do it.\n",
            "[01:40.000 --> 01:50.000]  I'm going to show you how to do it.\n",
            "[01:50.000 --> 01:58.000]  I'm going to show you how to do it.\n",
            "[01:58.000 --> 02:04.000]  I'm going to show you how to do it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1350 H 02 AUG 2023 (01) SPECIFING THE LANGUAGE**"
      ],
      "metadata": {
        "id": "zObSkSsiz7UP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper output/audio7_Vocals.wav --language Chinese --task translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzjBEA7d0ANY",
        "outputId": "545b3474-3e26-433a-e15e-c92798eab4df"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:30.000]  It's a good thing that I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I\n",
            "[00:30.000 --> 00:50.740]  Here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here, I'm here,\n",
            "[00:50.740 --> 01:20.740]  No, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no\n",
            "[01:20.740 --> 01:29.700]  no, no, no, no, no\n",
            "[01:29.700 --> 01:59.700]  I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't\n",
            "[01:59.700 --> 02:05.410]  I don't know what I'm talking about, I don't know\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1405 H   AS ON 02 AUG 2023 (01) (1)**"
      ],
      "metadata": {
        "id": "eU4dplVJ0hFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper output/audio8_Vocals.wav --task translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_noq6xjw0j4_",
        "outputId": "4c3ac8ce-c107-44b8-c4dc-c66e3dbab417"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Hawaiian\n",
            "[00:00.000 --> 00:30.000]  I don't know what I'm going to say, but I don't know what I'm going to say, but I don't know what I'm going to say, but I don't know what I'm going to say, but I don't know what I'm going to say, but I don't know what I'm going to say, but I don't know what I'm going to say, but I don't know what I'm going to say, but I don't know what I'm going to say, but I don't know what I'm going to say, but I don't know what I'm going to say, but I don't know what I'm going to say, but I don't know what I'm going to say, but I don't know what I'm going to say, but I don't know what I'm going to say, but I don't know what I'm going to say, but I don't know what I'm going to say, but I don't know what I'm going to say, but I don't know what I'm\n",
            "[00:30.000 --> 00:39.040]  going to say, but I don't know what I'm going to say, but I don't know what I'm going to\n",
            "[00:40.000 --> 00:56.920]  say, but I don't know what I'm going to say, but I don't know what I'm going to say, but I don't know what I'm\n",
            "[00:56.920 --> 01:26.920]  I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't know what I'm talking about, I don't\n",
            "[01:26.920 --> 01:31.120]  know what I'm talking about, I don't know what I'm talking about.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1405 H AS ON 02 AUG 2023 (01) (1) SPECIFING THE LANGUAGE**"
      ],
      "metadata": {
        "id": "cSO0NXZF00pA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper output/audio8_Vocals.wav --language Chinese --task translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHk2yA_e0336",
        "outputId": "f701d01f-772f-4d3d-cabe-62b0cc924896"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:02.000]  You are not going to be able to do it.\n",
            "[00:02.000 --> 00:04.000]  You are not going to be able to do it.\n",
            "[00:04.000 --> 00:06.000]  You are not going to be able to do it.\n",
            "[00:06.000 --> 00:08.000]  You are not going to be able to do it.\n",
            "[00:08.000 --> 00:10.000]  You are not going to be able to do it.\n",
            "[00:10.000 --> 00:12.000]  You are not going to be able to do it.\n",
            "[00:12.000 --> 00:14.000]  You are not going to be able to do it.\n",
            "[00:14.000 --> 00:16.000]  You are not going to be able to do it.\n",
            "[00:16.000 --> 00:18.000]  You are not going to be able to do it.\n",
            "[00:18.000 --> 00:20.000]  You are not going to be able to do it.\n",
            "[00:20.000 --> 00:22.000]  You are not going to be able to do it.\n",
            "[00:22.000 --> 00:24.000]  You are not going to be able to do it.\n",
            "[00:24.000 --> 00:26.000]  You are not going to be able to do it.\n",
            "[00:26.000 --> 00:28.000]  You are not going to be able to do it.\n",
            "[00:28.000 --> 00:30.000]  You are not going to be able to do it.\n",
            "[00:30.000 --> 00:32.000]  You are going to be able to do it.\n",
            "[00:32.000 --> 00:34.000]  You are not going to be able to do it.\n",
            "[00:34.000 --> 00:36.000]  You will not be able to do it.\n",
            "[00:36.000 --> 00:38.000]  You will not be able to do it.\n",
            "[00:38.000 --> 00:40.000]  You will not be able to do it.\n",
            "[00:40.000 --> 00:42.000]  You can't do it.\n",
            "[00:42.000 --> 00:44.000]  You are not going to be able to do it.\n",
            "[00:44.000 --> 00:46.000]  You will be able to do it.\n",
            "[00:46.000 --> 00:48.000]  You can't do it.\n",
            "[00:48.000 --> 00:50.000]  You are not going to be able to do it.\n",
            "[00:50.000 --> 00:52.000]  You are not going to be able to do it.\n",
            "[00:52.000 --> 00:54.000]  You are not going to be able to do it.\n",
            "[00:54.000 --> 00:58.000]  This is the first time I've seen a person like this in my life.\n",
            "[00:58.000 --> 01:02.000]  This is the first time I've seen a person like this in my life.\n",
            "[01:02.000 --> 01:06.000]  This is the first time I've seen a person like this in my life.\n",
            "[01:06.000 --> 01:10.000]  This is the first time I've seen a person like this in my life.\n",
            "[01:10.000 --> 01:14.000]  This is the first time I've seen a person like this in my life.\n",
            "[01:14.000 --> 01:18.000]  This is the first time I've seen a person like this in my life.\n",
            "[01:18.000 --> 01:22.000]  This is the first time I've seen a person like this in my life.\n",
            "[01:22.000 --> 01:27.000]  This is the first time I've seen a person like this in my life.\n",
            "[01:27.000 --> 01:31.000]  This is the first time I've seen a person like this in my life.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1635 H   AS ON 02 AUG 2023 (01) (1)**"
      ],
      "metadata": {
        "id": "1ZJcxH4p1Dav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper output/audio9_Vocals.wav --task translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSGGJzuN1Gl4",
        "outputId": "d488f2bf-ec10-4fd9-a350-773aa5806dcb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Sindhi\n",
            "[00:00.000 --> 00:04.000]  I don't know why I'm all over it.\n",
            "[00:04.000 --> 00:08.000]  If you think that I'm a person who can't do anything,\n",
            "[00:08.000 --> 00:12.000]  can't do anything, I can't do anything, I can't do anything,\n",
            "[00:12.000 --> 00:16.000]  I can't do anything, I can't do anything,\n",
            "[00:16.000 --> 00:20.000]  I can't do anything, I can't do anything, I can't do anything,\n",
            "[00:20.000 --> 00:24.000]  I can't do anything, I can't do anything, I can't do anything,\n",
            "[00:24.000 --> 00:28.000]  I can't do anything, I can't do anything,\n",
            "[00:28.000 --> 00:34.000]  I can't say anything,\n",
            "[00:34.000 --> 00:48.000]  but you must always come and do what is best in your life.\n",
            "[00:48.000 --> 00:52.000]  Before you go, you must always do what is best in your life.\n",
            "[00:52.000 --> 00:56.000]  That's the principle we have known.\n",
            "[00:56.000 --> 01:03.420]  What you are trying to do is\n",
            "[01:03.420 --> 01:11.920]  Wow.\n",
            "[01:11.920 --> 01:16.000]  I'm\n",
            "[01:16.000 --> 01:26.720]  Amen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1635 H AS ON 02 AUG 2023 (01) (1) SPECIFING THE LANGUAGE**"
      ],
      "metadata": {
        "id": "OffNtlOv1HFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper output/audio9_Vocals.wav --language Chinese --task translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7n5wj--P1Ml7",
        "outputId": "243da010-4cb0-4d61-cc38-b8f61b61522e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:04.000]  This is a very important thing.\n",
            "[00:04.000 --> 00:12.000]  If you want to go to China, you have to go to China.\n",
            "[00:12.000 --> 00:18.000]  If you want to go to China, you have to go to China.\n",
            "[00:18.000 --> 00:26.000]  If you want to go to China, you have to go to China.\n",
            "[00:26.000 --> 00:34.000]  If you want to go to China, you have to go to China.\n",
            "[00:34.000 --> 00:43.000]  If you want to go to China, you have to go to China.\n",
            "[00:43.000 --> 00:51.940]  I may have fallen illegitimate child, but it is difficult to get a child.\n",
            "[00:51.940 --> 00:55.360]  This is a due delay of the marriage couple.\n",
            "[00:55.500 --> 01:01.600]  So they've spent a place on their family's background.\n",
            "[01:01.600 --> 01:05.320]  We eat everything.\n",
            "[01:05.380 --> 01:10.520]  Just tell the sea-wrestling god what you want,\n",
            "[01:10.580 --> 01:15.260]  and tell people about his reality.\n",
            "[01:15.300 --> 01:18.960]  If God allows do that,\n",
            "[01:18.960 --> 01:23.600]  God can do whatever He wants.\n",
            "[01:23.620 --> 01:26.300]  Please call me.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1640 H  AS ON 02 AUG 2023 (02) (1)**"
      ],
      "metadata": {
        "id": "ef0x7b4R1S_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper output/audio10_Vocals.wav --task translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUVo30WA1WNZ",
        "outputId": "68d4f65b-cacb-46c1-b4d4-f21e0d425a14"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Myanmar\n",
            "[00:00.000 --> 00:03.160]  That's not going to happen.\n",
            "[00:03.240 --> 00:06.560]  It isn't going to happen.\n",
            "[00:06.640 --> 00:09.400]  It's not going to happen.\n",
            "[00:09.460 --> 00:12.840]  It's not going to happen.\n",
            "[00:12.880 --> 00:23.000]  Nothing of it is going to happen.\n",
            "[00:23.000 --> 00:27.640]  VMware is the most important organizations in the world,\n",
            "[00:27.640 --> 00:38.580]  so many active startup organizations have invited people to support innovation.\n",
            "[00:38.580 --> 00:42.240]  Where does innovation come from?\n",
            "[00:42.240 --> 00:48.220]  Sort out the idea of American people in India\n",
            "[00:48.220 --> 00:52.420]  building doncs and refurbiiing,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1640 H AS ON 02 AUG 2023 (02) (1) SPECIFING THE LANGUAGE**"
      ],
      "metadata": {
        "id": "I_ECzqWZ1ayA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper output/audio10_Vocals.wav --language Chinese --task translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8pWYQKo1aMK",
        "outputId": "f2dacc28-c7e6-4f78-c2dd-550c07e34ffc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:06.660]  If I am Face, I have to give up\n",
            "[00:06.660 --> 00:12.980]  If I am Face, I can't find myself\n",
            "[00:12.980 --> 00:16.900]  or not, I criticize\n",
            "[00:16.900 --> 00:20.640]  But I can't help\n",
            "[00:20.640 --> 00:23.280]  I am fine\n",
            "[00:23.280 --> 00:26.680]  is it gone?\n",
            "[00:26.680 --> 00:29.120]  I can say\n",
            "[00:29.120 --> 00:31.360]  Madam who has taken away the English rustic painting.\n",
            "[00:32.420 --> 00:37.300]  Is it a joke to not use it to draw things on the table?\n",
            "[00:38.740 --> 00:41.160]  Of course it is.\n",
            "[00:42.180 --> 00:44.840]  I am just here to do farming.\n",
            "[00:45.860 --> 00:47.260]  Come at all.\n",
            "[00:47.780 --> 00:48.840]  Here.\n",
            "[00:49.340 --> 00:50.240]  Come.\n"
          ]
        }
      ]
    }
  ]
}